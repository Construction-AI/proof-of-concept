services:
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    networks:
      - rag-network

  llamaindex-service:
    build:
      context: ./llamaindex-service
      dockerfile: Dockerfile
    container_name: llamaindex-service
    ports:
      - "8000:8000"
    environment:
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LLM_PROVIDER=${LLM_PROVIDER}
      - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL}
      - OLLAMA_MODEL=${OLLAMA_MODEL}
      - OLLAMA_URL=${OLLAMA_URL}
      - EXT_EMBEDDING_MODEL=${EXT_EMBEDDING_MODEL}
      - QDRANT_URL=${QDRANT_URL}
    volumes:
      - ./documents:/app/documents
      - ./schema:/app/schema
      - ./llamaindex-service:/app
    depends_on:
      - qdrant
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 1m30s
      timeout: 30s
      retries: 5
      start_period: 30s

  # ollama:
  #   build:
  #     context: ./ollama-service
  #     dockerfile: Dockerfile
  #   volumes:
  #     - ollama_storage:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   networks:
  #     - rag-network
  #   environment:
  #     - OLLAMA_EMBEDDING_MODEL=${OLLAMA_EMBEDDING_MODEL}
  #     - OLLAMA_MODEL=${OLLAMA_MODEL}

networks:
  rag-network:
    driver: bridge

volumes:
  qdrant_storage:
  ollama_storage: